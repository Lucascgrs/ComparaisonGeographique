# ============================================================================
# IMPORTS
# ============================================================================
import os
import sys
import argparse
import shutil
import requests
import numpy as np
import pandas as pd
import geopandas as gpd
import osmnx as ox
import shapely.geometry
from PIL import Image
from tqdm import tqdm
import sentinelhub
import warnings

# Ignorer les warnings g√©om√©triques mineurs
warnings.filterwarnings("ignore")

# On essaie d'importer les credentials, sinon on cr√©e un mock
try:
    import mycredentials
except ImportError:
    print("‚ö†Ô∏è mycredentials.py manquant. Certaines fonctions pourraient √©chouer.")
    class mycredentials:
        username = ""
        password = ""

# ============================================================================
# CONSTANTES : LISTE DES √âTATS DU BR√âSIL (Ordre Prioritaire D√©forestation)
# ============================================================================
# On commence par l'Amazonie L√©gale ("Legal Amazon") o√π se concentre la d√©forestation
BRAZIL_STATES = [
    "Par√°, Brazil",
    "Mato Grosso, Brazil",
    "Rond√¥nia, Brazil",
    "Amazonas, Brazil",
    "Acre, Brazil",
    "Maranh√£o, Brazil",
    "Roraima, Brazil",
    "Tocantins, Brazil",
    "Amap√°, Brazil",
    # Autres √©tats (Cerrado / Mata Atl√¢ntica)
    "Goi√°s, Brazil",
    "Bahia, Brazil",
    "Minas Gerais, Brazil",
    "Mato Grosso do Sul, Brazil",
    "Piau√≠, Brazil",
    "S√£o Paulo, Brazil",
    "Paran√°, Brazil",
    "Rio Grande do Sul, Brazil",
    "Santa Catarina, Brazil",
    "Cear√°, Brazil",
    "Rio de Janeiro, Brazil",
    "Pernambuco, Brazil",
    "Esp√≠rito Santo, Brazil",
    "Para√≠ba, Brazil",
    "Rio Grande do Norte, Brazil",
    "Alagoas, Brazil",
    "Sergipe, Brazil",
    "Distrito Federal, Brazil"
]

# ============================================================================
# MODULE 1: G√âOGRAPHIE & GESTION DE VILLES
# ============================================================================
class GeoManager:
    def __init__(self):
        self.municipalities = None
        self.current_aoi = None
        self.current_bbox = None
        self.current_name = None

    def get_municipalities_list(self, state_name, limit=None):
        """R√©cup√®re la liste des municipalit√©s pour un √©tat donn√©."""
        tqdm.write(f"üåç R√©cup√©ration des municipalit√©s pour : {state_name}...")
        try:
            # On r√©cup√®re les fronti√®res administratives niveau 8 (villes)
            gdf = ox.features_from_place(
                state_name,
                tags={'admin_level': '8', 'boundary': 'administrative'}
            )
            
            if 'name' not in gdf.columns and 'display_name' in gdf.columns:
                gdf['name'] = gdf['display_name']
            
            # Nettoyage
            gdf = gdf[gdf['name'].notna()]
            
            # Tri al√©atoire pour ne pas toujours faire les m√™mes si on met une limite
            # ou tri par taille (optionnel), ici on prend les premiers retourn√©s
            
            if limit and limit > 0:
                gdf = gdf.head(limit)
            
            self.municipalities = gdf
            tqdm.write(f"‚úÖ {len(gdf)} municipalit√©s trouv√©es dans {state_name}.")
            return gdf['name'].tolist()
            
        except Exception as e:
            tqdm.write(f"‚ùå Erreur r√©cup√©ration liste {state_name} : {e}")
            return []

    def set_current_municipality(self, name):
        """D√©finit la municipalit√© active pour l'analyse."""
        # Si la municipalit√© est dans le buffer charg√© (le cas normal dans la boucle)
        if self.municipalities is not None and name in self.municipalities['name'].values:
            self.current_aoi = self.municipalities[self.municipalities['name'] == name].iloc[[0]]
        else:
            # Fallback : g√©ocodage direct (pour le deep scan final si besoin)
            try:
                gdf = ox.geocode_to_gdf(f"{name}, Brazil")
                self.current_aoi = gdf.iloc[[0]]
            except:
                return False

        self.current_name = name
        self.current_bbox = self.current_aoi.total_bounds # (minx, miny, maxx, maxy)
        # Note: SentinelHub g√®re le bbox en liste, pas besoin de polygone shapely ici
        return True

    def save_current_map(self, output_dir):
        """Sauvegarde la carte HTML."""
        filename = os.path.join(output_dir, "map_location.html")
        try:
            m = self.current_aoi.explore(color='red', tiles='OpenStreetMap', style_kwds={'fillOpacity': 0.1})
            m.save(filename)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur carte HTML : {e}")


# ============================================================================
# MODULE 2: SENTINEL HUB (ANALYSE)
# ============================================================================
class SentinelHubProcessor:
    def __init__(self, bbox, resolution=500):
        self.config = sentinelhub.SHConfig("cdse")
        self.aoi_bbox_sh = sentinelhub.BBox(bbox=list(bbox), crs=sentinelhub.CRS.WGS84)
        
        # Calcul dynamique taille image
        try:
            self.aoi_size = sentinelhub.bbox_to_dimensions(self.aoi_bbox_sh, resolution=resolution)
            # S√©curit√© taille max (SentinelHub bloque souvent > 2500px en free tier/standard)
            max_px = 2500
            if max(self.aoi_size) > max_px:
                scale = max_px / max(self.aoi_size)
                self.aoi_size = (int(self.aoi_size[0] * scale), int(self.aoi_size[1] * scale))
        except:
            self.aoi_size = (100, 100)

    def get_image(self, evalscript, start_date, end_date, brightness=1.0, filename=None):
        request = sentinelhub.SentinelHubRequest(
            evalscript=evalscript,
            input_data=[
                sentinelhub.SentinelHubRequest.input_data(
                    data_collection=sentinelhub.DataCollection.SENTINEL2_L2A.define_from(
                        name="s2", service_url="https://sh.dataspace.copernicus.eu"
                    ),
                    time_interval=(start_date, end_date),
                    other_args={"dataFilter": {"mosaickingOrder": "leastCC"}}
                )
            ],
            responses=[sentinelhub.SentinelHubRequest.output_response("default", sentinelhub.MimeType.TIFF)],
            bbox=self.aoi_bbox_sh,
            size=self.aoi_size,
            config=self.config,
        )
        
        try:
            data = request.get_data()
            if not data: return None
            img_array = data[0]
            
            if brightness != 1.0:
                img_array = np.uint8((img_array * brightness).clip(0, 255))
                
            if filename:
                to_save = img_array if img_array.shape[-1] != 1 else img_array.squeeze()
                Image.fromarray(to_save).save(filename)
                
            return img_array
        except Exception as e:
            # tqdm.write(f"‚ö†Ô∏è Erreur SH : {e}")
            return None

# ============================================================================
# EVALSCRIPTS
# ============================================================================
EVALSCRIPTS = {
    "TRUE_COLOR": """
        //VERSION=3
        function setup() { return { input: [{ bands: ["B02", "B03", "B04"] }], output: { bands: 3 } }; }
        function evaluatePixel(sample) { return [sample.B04, sample.B03, sample.B02]; }
    """,
    "NDVI": """
        //VERSION=3
        function setup() { return { input: [{ bands: ["B04", "B08"] }], output: { bands: 4 } }; }
        const whiteGreen = [[1.0, 0xFFFFFF], [0.5, 0x000000], [0.0, 0x00FF00]];
        let viz = new ColorGradientVisualizer(whiteGreen, -1.0, 1.0);
        function evaluatePixel(samples) {
            let val = ((samples.B08 + samples.B04)==0) ? 0 : ((samples.B08 - samples.B04) / (samples.B08 + samples.B04));
            let col = viz.process(val); col.push(255); return col;
        }
    """,
    "BURNED_INDEX_RAW": """
        //VERSION=3
        function setup() { return { input: [{ bands: ["B08", "B12"] }], output: { bands: 1, sampleType: SampleType.FLOAT32 } }; }
        function evaluatePixel(samples) {
            return [((samples.B08 + samples.B12)==0) ? 0 : ((samples.B08 - samples.B12) / (samples.B08 + samples.B12))];
        }
    """
}

# ============================================================================
# CORE LOGIC
# ============================================================================

def analyze_municipality(geo, name, args, is_deep_scan=False):
    """Retourne un score de d√©forestation (0-100). G√©n√®re des fichiers si is_deep_scan=True."""
    try:
        if not geo.set_current_municipality(name):
            return 0

        # Dossier de sortie (seulement pour le deep scan)
        output_dir = None
        if is_deep_scan:
            clean_name = name.replace(" ", "_").replace(",", "")
            output_dir = os.path.join("results", clean_name)
            os.makedirs(output_dir, exist_ok=True)
            geo.save_current_map(output_dir)
            tqdm.write(f"üìÇ G√©n√©ration rapport pour {name}...")

        # R√©solution adaptative
        res = args.resolution if is_deep_scan else args.scan_resolution
        sh_proc = SentinelHubProcessor(geo.current_bbox, resolution=res)
        
        interval_before = (f"{args.year_before}-07-01", f"{args.year_before}-09-30")
        interval_after = (f"{args.year_after}-07-01", f"{args.year_after}-09-30")

        # 1. Calcul Score (Burn Index)
        raw_before = sh_proc.get_image(EVALSCRIPTS["BURNED_INDEX_RAW"], *interval_before)
        raw_after = sh_proc.get_image(EVALSCRIPTS["BURNED_INDEX_RAW"], *interval_after)

        score = 0
        if raw_before is not None and raw_after is not None:
            difference = raw_before - raw_after
            # On compte les pixels > seuil (0.2)
            affected_pixels = np.sum(difference > 0.25)
            total_pixels = difference.size
            score = (affected_pixels / total_pixels) * 100
        else:
            return 0

        if not is_deep_scan:
            return score

        # 2. G√©n√©ration Deep Scan
        Image.fromarray(raw_before if raw_before.shape[-1] != 1 else raw_before.squeeze()).save(os.path.join(output_dir, "burn_raw_before.tif"))
        
        img_after = sh_proc.get_image(EVALSCRIPTS["TRUE_COLOR"], *interval_after, brightness=3.5, filename=os.path.join(output_dir, "true_color_after.png"))
        sh_proc.get_image(EVALSCRIPTS["TRUE_COLOR"], *interval_before, brightness=3.5, filename=os.path.join(output_dir, "true_color_before.png"))
        
        sh_proc.get_image(EVALSCRIPTS["NDVI"], *interval_before, filename=os.path.join(output_dir, "ndvi_before.png"))
        sh_proc.get_image(EVALSCRIPTS["NDVI"], *interval_after, filename=os.path.join(output_dir, "ndvi_after.png"))

        # Composite
        if img_after is not None and raw_before is not None and raw_after is not None:
            composite = np.array(img_after)
            diff = raw_before - raw_after
            if diff.shape[:2] == composite.shape[:2]:
                composite[diff > 0.25] = [255, 128, 0]
                composite[diff > 0.60] = [255, 0, 0]
                Image.fromarray(composite).save(os.path.join(output_dir, "analysis_composite.png"))

        return score

    except Exception as e:
        # tqdm.write(f"Erreur {name}: {e}")
        return 0


def main():
    parser = argparse.ArgumentParser(description="Scanner National de D√©forestation - Br√©sil")
    parser.add_argument("--max_states", type=int, default=1, help="Nombre d'√©tats √† scanner (dans l'ordre prioritaire)")
    parser.add_argument("--limit_per_state", type=int, default=5, help="Nombre de villes √† scanner par √©tat")
    parser.add_argument("--top_n", type=int, default=2, help="Top N final des pires villes √† analyser en d√©tail")
    
    parser.add_argument("--year_before", type=str, default="2018")
    parser.add_argument("--year_after", type=str, default="2021")
    parser.add_argument("--scan_resolution", type=int, default=1000, help="R√©solution du scan (m)")
    parser.add_argument("--resolution", type=int, default=200, help="R√©solution du deep scan (m)")
    
    args = parser.parse_args()

    # S√©lection des √©tats
    states_to_scan = BRAZIL_STATES[:args.max_states]
    
    print(f"üöÄ D√âMARRAGE DU SCAN GLOBAL ({args.year_before} -> {args.year_after})")
    print(f"üìç √âtats cibl√©s ({len(states_to_scan)}): {', '.join([s.split(',')[0] for s in states_to_scan])}")
    print(f"‚ö° R√©solution scan: {args.scan_resolution}m | Limite: {args.limit_per_state} villes/√©tat")
    print("="*60)

    geo = GeoManager()
    global_scores = {}

    # --- BOUCLE SUR LES √âTATS ---
    for state_name in states_to_scan:
        muni_list = geo.get_municipalities_list(state_name, limit=args.limit_per_state)
        
        if not muni_list:
            continue
            
        print(f"   üîç Analyse de {len(muni_list)} villes dans {state_name}...")
        
        # Barre de progression par √©tat
        for name in tqdm(muni_list, desc=f"Scan {state_name.split(',')[0]}", leave=False):
            score = analyze_municipality(geo, name, args, is_deep_scan=False)
            
            # On garde le score s'il est pertinent
            if score > 0:
                global_scores[name] = score
                # Affichage dynamique des "gros" cas
                if score > 2.0:
                    tqdm.write(f"      ‚ö†Ô∏è  Alert: {name} -> Score: {score:.2f}")

    # --- R√âSULTATS GLOBAUX ---
    sorted_scores = sorted(global_scores.items(), key=lambda x: x[1], reverse=True)
    
    print("\n" + "="*60)
    print(f"üèÜ CLASSEMENT NATIONAL (TOP 20) - Score de changement")
    print("="*60)
    for i, (name, score) in enumerate(sorted_scores[:20]):
        print(f"{i+1}. {name:<30} : {score:.2f}")

    # --- DEEP SCAN FINAL ---
    print("\n" + "="*60)
    print(f"üî¨ G√âN√âRATION DES RAPPORTS D√âTAILL√âS (TOP {args.top_n})")
    print("="*60)
    
    for name, score in sorted_scores[:args.top_n]:
        analyze_municipality(geo, name, args, is_deep_scan=True)
    
    print(f"\n‚úÖ Analyse termin√©e. Voir le dossier 'results/'.")

if __name__ == "__main__":
    main()